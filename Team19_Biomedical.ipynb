{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba94244-aad0-4e1a-bea3-15de233d5b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy matplotlib scikit-image scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffc6167-0eda-4435-89c6-01a08a7a968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists: C:\\Users\\Admin\\Downloads\\dataverse_files\\ZT111_4_A\\ZT111_4_A\n",
      "Files in dataset folder: ['clustered_data', 'processed_data', 'ZT111_4_A_1_12.jpg', 'ZT111_4_A_1_13.jpg', 'ZT111_4_A_1_14.jpg', 'ZT111_4_A_1_2.jpg', 'ZT111_4_A_1_5.jpg', 'ZT111_4_A_1_6.jpg', 'ZT111_4_A_1_7.jpg', 'ZT111_4_A_1_8.jpg', 'ZT111_4_A_1_9.jpg', 'ZT111_4_A_2_1.jpg', 'ZT111_4_A_2_10.jpg', 'ZT111_4_A_2_13.jpg', 'ZT111_4_A_2_14.jpg', 'ZT111_4_A_2_2.jpg', 'ZT111_4_A_2_8.jpg', 'ZT111_4_A_3_1.jpg', 'ZT111_4_A_3_10.jpg', 'ZT111_4_A_3_11.jpg', 'ZT111_4_A_3_12.jpg', 'ZT111_4_A_3_13.jpg', 'ZT111_4_A_3_2.jpg', 'ZT111_4_A_3_4.jpg', 'ZT111_4_A_3_5.jpg', 'ZT111_4_A_3_7.jpg', 'ZT111_4_A_3_8.jpg', 'ZT111_4_A_3_9.jpg', 'ZT111_4_A_4_11.jpg', 'ZT111_4_A_4_13.jpg', 'ZT111_4_A_4_14.jpg', 'ZT111_4_A_4_2.jpg', 'ZT111_4_A_4_4.jpg', 'ZT111_4_A_4_5.jpg', 'ZT111_4_A_4_6.jpg', 'ZT111_4_A_4_8.jpg', 'ZT111_4_A_4_9.jpg', 'ZT111_4_A_5_10.jpg', 'ZT111_4_A_5_11.jpg', 'ZT111_4_A_5_12.jpg', 'ZT111_4_A_5_13.jpg', 'ZT111_4_A_5_14.jpg', 'ZT111_4_A_5_3.jpg', 'ZT111_4_A_5_5.jpg', 'ZT111_4_A_5_7.jpg', 'ZT111_4_A_5_9.jpg', 'ZT111_4_A_6_10.jpg', 'ZT111_4_A_6_11.jpg', 'ZT111_4_A_6_12.jpg', 'ZT111_4_A_6_13.jpg', 'ZT111_4_A_6_14.jpg', 'ZT111_4_A_6_4.jpg', 'ZT111_4_A_6_5.jpg', 'ZT111_4_A_6_6.jpg', 'ZT111_4_A_6_7.jpg', 'ZT111_4_A_6_8.jpg', 'ZT111_4_A_6_9.jpg', 'ZT111_4_A_7_1.jpg', 'ZT111_4_A_7_10.jpg', 'ZT111_4_A_7_11.jpg', 'ZT111_4_A_7_12.jpg', 'ZT111_4_A_7_13.jpg', 'ZT111_4_A_7_14.jpg', 'ZT111_4_A_7_2.jpg', 'ZT111_4_A_7_5.jpg', 'ZT111_4_A_7_6.jpg', 'ZT111_4_A_7_7.jpg', 'ZT111_4_A_8_10.jpg', 'ZT111_4_A_8_11.jpg', 'ZT111_4_A_8_12.jpg', 'ZT111_4_A_8_13.jpg', 'ZT111_4_A_8_14.jpg', 'ZT111_4_A_8_3.jpg', 'ZT111_4_A_8_4.jpg', 'ZT111_4_A_8_5.jpg', 'ZT111_4_A_8_6.jpg', 'ZT111_4_A_8_7.jpg', 'ZT111_4_A_8_8.jpg', 'ZT111_4_A_8_9.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 77/77 [2:06:54<00:00, 98.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superpixel images and data saved to C:\\Users\\Admin\\Downloads\\dataverse_files\\ZT111_4_A\\ZT111_4_A\\processed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.measure import regionprops\n",
    "from tqdm import tqdm  # For progress bar\n",
    "# Define dataset path\n",
    "dataset_path = r\"C:\\Users\\Admin\\Downloads\\dataverse_files\\ZT111_4_A\\ZT111_4_A\"\n",
    "output_folder = os.path.join(dataset_path, \"processed_data\")\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "# Check if the path exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Error: The path '{dataset_path}' does not exist.\")\n",
    "else:\n",
    "    print(f\"Path exists: {dataset_path}\")\n",
    "    # List available files\n",
    "    all_files = os.listdir(dataset_path)\n",
    "    print(\"Files in dataset folder:\", all_files)\n",
    "    # Filter only image files\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory!\")\n",
    "    else:\n",
    "        dataset_info = {}\n",
    "        # Loop through each image\n",
    "        for image_file in tqdm(image_files, desc=\"Processing Images\"):\n",
    "            image_path = os.path.join(dataset_path, image_file)\n",
    "            # Load and convert image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Generate superpixels using SLIC algorithm\n",
    "            num_segments = 1000  # You can adjust this number\n",
    "            segments = slic(image, n_segments=num_segments, compactness=30, start_label=1)\n",
    "            # Store information for each superpixel\n",
    "            superpixel_info = {\n",
    "                \"image_name\": image_file,\n",
    "                \"superpixels\": []\n",
    "            }\n",
    "            # Create a copy for the superpixel image\n",
    "            superpixel_image = np.zeros_like(image)\n",
    "            for region in regionprops(segments, intensity_image=rgb2lab(image)):\n",
    "                centroid = region.centroid\n",
    "                coords = region.coords  # Pixel coordinates in superpixel\n",
    "                # Extract pixel values\n",
    "                pixel_values = image[coords[:, 0], coords[:, 1]]\n",
    "                # Calculate color statistics\n",
    "                mean_color = np.mean(pixel_values, axis=0).astype(int).tolist()\n",
    "                std_color = np.std(pixel_values, axis=0).tolist()\n",
    "                cov_color = np.cov(pixel_values.T).tolist()\n",
    "                # Fill superpixel region with mean color\n",
    "                for coord in coords:\n",
    "                    superpixel_image[coord[0], coord[1]] = mean_color\n",
    "                superpixel_info[\"superpixels\"].append({\n",
    "                    \"centroid\": [int(centroid[0]), int(centroid[1])],\n",
    "                    \"mean_color\": mean_color,\n",
    "                    \"std_color\": std_color,\n",
    "                    \"covariance_color\": cov_color\n",
    "                })\n",
    "            # Add label map (superpixel segmentation mask)\n",
    "            superpixel_info[\"label_map\"] = segments.tolist()\n",
    "            # Save the superpixel information into a JSON file\n",
    "            json_filename = os.path.splitext(image_file)[0] + \"_superpixel_info.json\"\n",
    "            json_output_path = os.path.join(output_folder, json_filename)\n",
    "            with open(json_output_path, 'w') as json_file:\n",
    "                json.dump(superpixel_info, json_file, indent=4)\n",
    "            # Save the superpixel image (each superpixel filled with mean color)\n",
    "            superpixel_image_path = os.path.join(output_folder, os.path.splitext(image_file)[0] + \"_superpixel.png\")\n",
    "            plt.imsave(superpixel_image_path, superpixel_image)\n",
    "        print(f\"Superpixel images and data saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1eced1e-049a-4cd3-8046-c8f3f5e08c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.11.0.86)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-image in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python scikit-image scikit-learn matplotlib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57fa5f-7544-47f4-968b-98648ac79ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77 superpixel images. Starting clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   0%|                                                                                                                        | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_12_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   1%|█▍                                                                                                           | 1/77 [03:21<4:14:41, 201.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_13_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   3%|██▊                                                                                                          | 2/77 [07:09<4:31:17, 217.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_14_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   4%|████▏                                                                                                        | 3/77 [10:32<4:19:51, 210.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_2_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   5%|█████▋                                                                                                       | 4/77 [13:46<4:08:32, 204.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_5_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   6%|███████                                                                                                      | 5/77 [17:21<4:09:48, 208.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_6_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   8%|████████▍                                                                                                    | 6/77 [20:24<3:56:11, 199.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Mean Shift to ZT111_4_A_1_7_superpixel.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering Images:   9%|█████████▉                                                                                                   | 7/77 [23:57<3:57:52, 203.89s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans, MeanShift, estimate_bandwidth\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # Progress bar\n",
    " \n",
    "# Define dataset paths\n",
    "dataset_path = r\"C:\\Users\\Admin\\Downloads\\dataverse_files\\ZT111_4_A\\ZT111_4_A\"\n",
    "processed_folder = os.path.join(dataset_path, \"processed_data\")\n",
    "clustered_folder = os.path.join(dataset_path, \"clustered_data\")\n",
    " \n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(clustered_folder, exist_ok=True)\n",
    " \n",
    "# List available images\n",
    "all_files = os.listdir(processed_folder)\n",
    "superpixel_images = [f for f in all_files if f.endswith(\"_superpixel.png\")]\n",
    " \n",
    "if not superpixel_images:\n",
    "    print(\"No superpixel images found in the directory!\")\n",
    "    exit()\n",
    " \n",
    "print(f\"Found {len(superpixel_images)} superpixel images. Starting clustering...\")\n",
    " \n",
    "# Parameters\n",
    "N_CLUSTERS = 3         # Number of clusters for KMeans & GMM\n",
    "N_TREES = 50           # Random Forest trees\n",
    "TEST_SIZE = 0.005      # Use 0.5% pixels for RF training\n",
    "BATCH_SIZE = 5000      # MiniBatchKMeans batch size\n",
    " \n",
    "# Process each image\n",
    "for image_file in tqdm(superpixel_images, desc=\"Clustering Images\"):\n",
    "    image_path = os.path.join(processed_folder, image_file)\n",
    " \n",
    "    try:\n",
    "        # Load image with reduced resolution (2x smaller)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_REDUCED_COLOR_2)\n",
    " \n",
    "        if image is None:\n",
    "            print(f\"Skipping {image_file} (could not load).\")\n",
    "            continue\n",
    " \n",
    "        # Convert to float and normalize\n",
    "        pixels = image.reshape(-1, 3).astype(np.float32) / 255.0\n",
    " \n",
    "        # --- Step 1: Apply MiniBatch KMeans ---\n",
    "        kmeans = MiniBatchKMeans(n_clusters=N_CLUSTERS, batch_size=BATCH_SIZE, random_state=42)\n",
    "        kmeans_labels = kmeans.fit_predict(pixels)\n",
    "        clustered_kmeans = kmeans_labels.reshape(image.shape[:2])\n",
    " \n",
    "        # --- Step 2: Train Random Forest on KMeans labels ---\n",
    "        X_train, _, y_train, _ = train_test_split(pixels, kmeans_labels, test_size=TEST_SIZE, random_state=42)\n",
    "        rf = RandomForestClassifier(n_estimators=N_TREES, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rf_labels = rf.predict(pixels)\n",
    "        clustered_rf = rf_labels.reshape(image.shape[:2])\n",
    " \n",
    "        # --- Step 3: Apply Gaussian Mixture Model (GMM) ---\n",
    "        gmm = GaussianMixture(n_components=N_CLUSTERS, covariance_type=\"full\", random_state=42)\n",
    "        gmm_labels = gmm.fit_predict(pixels)\n",
    "        clustered_gmm = gmm_labels.reshape(image.shape[:2])\n",
    " \n",
    "        # --- Step 4: Apply Mean Shift ---\n",
    "        print(f\"Applying Mean Shift to {image_file}...\")\n",
    " \n",
    "        # Estimate bandwidth automatically (adaptive clustering)\n",
    "        bandwidth = estimate_bandwidth(pixels, quantile=0.1, n_samples=5000)\n",
    "        if bandwidth is None or bandwidth <= 0:\n",
    "            print(f\"Skipping {image_file}: Bandwidth estimation failed.\")\n",
    "            continue\n",
    " \n",
    "        # Mean Shift clustering\n",
    "        mean_shift = MeanShift(bandwidth=bandwidth, bin_seeding=True, n_jobs=-1)\n",
    "        mean_shift_labels = mean_shift.fit_predict(pixels)\n",
    "        clustered_meanshift = mean_shift_labels.reshape(image.shape[:2])\n",
    " \n",
    "        # --- Step 5: Save Clustered Images ---\n",
    "        output_kmeans = os.path.join(clustered_folder, f\"clustered_kmeans_{image_file}\")\n",
    "        output_rf = os.path.join(clustered_folder, f\"clustered_rf_{image_file}\")\n",
    "        output_gmm = os.path.join(clustered_folder, f\"clustered_gmm_{image_file}\")\n",
    "        output_meanshift = os.path.join(clustered_folder, f\"clustered_meanshift_{image_file}\")\n",
    " \n",
    "        plt.imsave(output_kmeans, clustered_kmeans, cmap='viridis')\n",
    "        plt.imsave(output_rf, clustered_rf, cmap='viridis')\n",
    "        plt.imsave(output_gmm, clustered_gmm, cmap='viridis')\n",
    "        plt.imsave(output_meanshift, clustered_meanshift, cmap='viridis')\n",
    " \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_file}: {e}\")\n",
    " \n",
    "print(f\"✅ Clustering completed! Results saved in {clustered_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd22d5c-ee16-406b-9852-ed67ddff2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Image  KMeans Std  RandomForest Std    GMM Std  \\\n",
      "0    ZT111_4_A_7_6_superpixel.png   60.528326         60.528326  63.714327   \n",
      "1    ZT111_4_A_5_7_superpixel.png   62.023179         62.023179  63.853873   \n",
      "2    ZT111_4_A_1_5_superpixel.png   61.797490         61.797490  73.754928   \n",
      "3    ZT111_4_A_3_1_superpixel.png   79.401160         79.401160  56.202391   \n",
      "4    ZT111_4_A_6_8_superpixel.png   74.369709         74.369709  75.746186   \n",
      "..                            ...         ...               ...        ...   \n",
      "72   ZT111_4_A_3_8_superpixel.png   76.914896         76.914896  77.777664   \n",
      "73   ZT111_4_A_4_6_superpixel.png   76.532258         76.532258  74.663435   \n",
      "74   ZT111_4_A_1_8_superpixel.png   81.746193         81.746193  67.150645   \n",
      "75  ZT111_4_A_5_11_superpixel.png   74.026812         74.026812  75.221828   \n",
      "76   ZT111_4_A_7_5_superpixel.png   81.971927         81.971927  68.311263   \n",
      "\n",
      "    MeanShift Std Best Method  Best Std Dev  \n",
      "0       44.425900   MeanShift     44.425900  \n",
      "1       25.880284   MeanShift     25.880284  \n",
      "2       40.889824   MeanShift     40.889824  \n",
      "3       37.931870   MeanShift     37.931870  \n",
      "4       43.042034   MeanShift     43.042034  \n",
      "..            ...         ...           ...  \n",
      "72      28.913080   MeanShift     28.913080  \n",
      "73      41.430421   MeanShift     41.430421  \n",
      "74      42.390325   MeanShift     42.390325  \n",
      "75      37.171921   MeanShift     37.171921  \n",
      "76      40.580883   MeanShift     40.580883  \n",
      "\n",
      "[77 rows x 7 columns]\n",
      "✅ Clustering standard deviation analysis completed! Results saved in clustering_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# Define the clustered image directory\n",
    "clustered_folder = r\"C:\\Users\\Admin\\Downloads\\dataverse_files\\ZT111_4_A\\ZT111_4_A\\clustered_data\"\n",
    " \n",
    "# Ensure the directory exists before proceeding\n",
    "if not os.path.exists(clustered_folder):\n",
    "    print(f\"❌ Directory not found: {clustered_folder}\")\n",
    "else:\n",
    "    # List all clustered images\n",
    "    all_files = os.listdir(clustered_folder)\n",
    "    unique_images = set(f.split(\"_\", 2)[-1] for f in all_files if f.endswith(\".png\"))  # Extract unique base image names\n",
    " \n",
    "    # Prepare results storage\n",
    "    results = []\n",
    " \n",
    "    # Iterate over each unique image and compute standard deviation for clustering methods\n",
    "    for image_name in unique_images:\n",
    "        image_paths = {\n",
    "            \"KMeans\": os.path.join(clustered_folder, f\"clustered_kmeans_{image_name}\"),\n",
    "            \"RandomForest\": os.path.join(clustered_folder, f\"clustered_rf_{image_name}\"),\n",
    "            \"GMM\": os.path.join(clustered_folder, f\"clustered_gmm_{image_name}\"),\n",
    "            \"MeanShift\": os.path.join(clustered_folder, f\"clustered_meanshift_{image_name}\")  # Updated Mean Shift path\n",
    "        }\n",
    " \n",
    "        std_values = {}\n",
    " \n",
    "        for method, path in image_paths.items():\n",
    "            if os.path.exists(path):\n",
    "                clustered_image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                if clustered_image is not None:\n",
    "                    std_values[method] = np.std(clustered_image)\n",
    "                else:\n",
    "                    std_values[method] = None\n",
    "            else:\n",
    "                std_values[method] = None\n",
    " \n",
    "        # Find the best clustering method for this image\n",
    "        valid_methods = {k: v for k, v in std_values.items() if v is not None}\n",
    " \n",
    "        if valid_methods:\n",
    "            best_method = min(valid_methods, key=valid_methods.get)\n",
    "            best_std = valid_methods[best_method]\n",
    "        else:\n",
    "            best_method = None\n",
    "            best_std = None\n",
    " \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Image\": image_name,\n",
    "            \"KMeans Std\": std_values.get(\"KMeans\"),\n",
    "            \"RandomForest Std\": std_values.get(\"RandomForest\"),\n",
    "            \"GMM Std\": std_values.get(\"GMM\"),\n",
    "            \"MeanShift Std\": std_values.get(\"MeanShift\"),\n",
    "            \"Best Method\": best_method,\n",
    "            \"Best Std Dev\": best_std\n",
    "        })\n",
    " \n",
    "    # Convert to DataFrame and display results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)  # Print the DataFrame for console viewing\n",
    "    df_results.to_csv(\"clustering_results.csv\", index=False)  # Save results as CSV for easier access\n",
    " \n",
    "print(\"✅ Clustering standard deviation analysis completed! Results saved in clustering_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264778be-a602-46bd-b05e-6ab933974146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
